---
title: OpenTelemetry Integration
---

AI agents create unpredictable usage patterns and complex request flows that are hard to monitor with traditional methods. The Apollo MCP Server's OpenTelemetry integration provides the visibility you need to run a reliable service for AI agents.

## **What You Can Monitor**

- **Agent behavior**: Which tools and operations are used most frequently
- **Performance**: Response times and bottlenecks across tool executions and GraphQL operations  
- **Reliability**: Error rates, failed operations, and request success patterns
- **Distributed request flows**: Complete traces from agent request through your Apollo Router and subgraphs, with automatic trace context propagation

## **How It Works**

The server exports metrics, traces, and events using the OpenTelemetry Protocol (OTLP), ensuring compatibility with your existing observability stack and seamless integration with other instrumented Apollo services.

## Usage Guide

### **Quick Start: Local Development**

The fastest way to see Apollo MCP Server telemetry in action is with a local setup that requires only Docker.

**ðŸš€ 5-minute setup:**
1. **Start local observability stack**: `docker run -p 3000:3000 -p 4317:4317 -p 4318:4318 --rm -ti grafana/otel-lgtm`
2. **Add telemetry config** to your `config.yaml`:
   ```yaml
   telemetry:
     exporters:
       metrics:
         otlp:
           endpoint: "http://localhost:4318/v1/metrics"
           protocol: "http/protobuf"
       tracing:
         otlp:
           endpoint: "http://localhost:4318/v1/traces" 
           protocol: "http/protobuf"
   ```
3. **Restart your MCP server** with the updated config
4. **Open Grafana** at http://localhost:3000 (admin/admin) and explore your telemetry data

For detailed steps and dashboard examples, see the [complete Grafana setup guide](guides/telemetry-grafana.mdx).

### **Production Deployment**

For production environments, configure the `endpoint` and `protocol` values to point to your observability infrastructure:

- **OpenTelemetry Collector**: See [OpenTelemetry deployment patterns](https://opentelemetry.io/docs/collector/deployment/)
- **Vendor-specific setup**: Consult your observability provider's OTLP integration documentation:
  - [Datadog OTLP](https://docs.datadoghq.com/tracing/setup_overview/open_standards/otlp_ingest_in_datadog/)  
  - [New Relic OTLP](https://docs.newrelic.com/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-setup/)
  - [AWS OTLP](https://aws-otel.github.io/docs/introduction)

**Configuration tips:**
- Set `ENVIRONMENT=production` for proper resource tagging
- Use secure HTTPS endpoints for production data
- Consider sampling for high-traffic environments

## Configuration Reference

The OpenTelemetry integration is configured via the `telemetry` section in your config.yaml file.

### **Basic Configuration**

| Parameter | Type | Description | Default |
| :--- | :--- | :--- | :--- |
| service_name | String | The service name in telemetry data. | `apollo-mcp-server` |
| version | String | The service version in telemetry data. | Current crate version |
| exporters | Object | Configuration for telemetry exporters. | `null` (no telemetry) |

### **Environment Variables**

| Variable | Description | Default |
| :--- | :--- | :--- |
| `ENVIRONMENT` | Sets the deployment environment for telemetry resource attributes. | `development` |

### **Automatic Resource Attributes**

The server automatically sets these OpenTelemetry resource attributes:

| Attribute | Value | Purpose |
| :--- | :--- | :--- |
| `service.name` | From `service_name` config | Service identification |
| `service.version` | From `version` config | Service version tracking |
| `deployment.environment.name` | From `ENVIRONMENT` variable | Environment correlation (dev, staging, prod) |

### **Exporters Configuration**

`exporters`

| Parameter | Type | Description |
| :--- | :--- | :--- |
| metrics | Object | Configuration for metrics exporters. |
| tracing | Object | Configuration for tracing exporters. |

`metrics.otlp` / `tracing.otlp`

| Parameter | Type | Description | Default |
| :--- | :--- | :--- | :--- |
| endpoint | String | The OTLP endpoint to send data to. | `http://localhost:4317` |
| protocol | String | The OTLP protocol to use. Supported values are `grpc` and `http/protobuf`. | `grpc` |


## Emitted Metrics

The server emits the following custom metrics, which are invaluable for monitoring and alerting. All duration metrics are in milliseconds.

| Metric Name | Type | Description | Attributes |
|---|---|---|---|
| `apollo.mcp.initialize.count` | Counter | Incremented for each `initialize` request. | (none) |
| `apollo.mcp.list_tools.count` | Counter | Incremented for each `list_tools` request. | (none) |
| `apollo.mcp.get_info.count` | Counter | Incremented for each `get_info` request. | (none) |
| `apollo.mcp.tool.count` | Counter | Incremented for each tool call. | `tool_name`, `success` (bool) |
| `apollo.mcp.tool.duration` | Histogram | Measures the execution duration of each tool call. | `tool_name`, `success` (bool) |
| `apollo.mcp.operation.count`| Counter | Incremented for each downstream GraphQL operation executed by a tool. | `operation.id`, `operation.type` ("persisted_query" or "operation"), `success` (bool) |
| `apollo.mcp.operation.duration`| Histogram | Measures the round-trip duration of each downstream GraphQL operation. | `operation.id`, `operation.type`, `success` (bool) |

In addition to these custom metrics, the server also emits standard [HTTP server metrics](https://opentelemetry.io/docs/specs/semconv/http/http-metrics/) (e.g., `http.server.duration`, `http.server.active_requests`) courtesy of the `axum-otel-metrics` library.


## Emitted Traces

Spans are generated for the following actions:

*   **Incoming HTTP Requests**: A root span is created for every HTTP request to the MCP server.
*   **MCP Handler Methods**: Nested spans are created for each of the main MCP protocol methods (`initialize`, `call_tool`, `list_tools`).
*   **Tool Execution**: `call_tool` spans contain nested spans for the specific tool being executed (e.g., `introspect`, `search`, or a custom GraphQL operation).
*   **Downstream GraphQL Calls**: The `execute` tool and custom operation tools create child spans for their outgoing `reqwest` HTTP calls, capturing the duration of the downstream request. The `traceparent` and `tracestate` headers are propagated automatically, enabling distributed traces.
