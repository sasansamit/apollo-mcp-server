---
title: OpenTelemetry Integration
---

AI agents create unpredictable usage patterns and complex request flows that are hard to monitor with traditional methods. The Apollo MCP Server's OpenTelemetry integration provides the visibility you need to run a reliable service for AI agents.

## **What You Can Monitor**

- **Agent behavior**: Which tools and operations are used most frequently
- **Performance**: Response times and bottlenecks across tool executions and GraphQL operations  
- **Reliability**: Error rates, failed operations, and request success patterns
- **Distributed request flows**: Complete traces from agent request through your Apollo Router and subgraphs, with automatic trace context propagation

## **How It Works**

The server exports metrics, traces, and events using the OpenTelemetry Protocol (OTLP), ensuring compatibility with your existing observability stack and seamless integration with other instrumented Apollo services.

## Usage Guide

To start exporting telemetry from the Apollo MCP Server, you need an OpenTelemetry Collector to which the MCP server can export metrics and traces to.
These are often run as side cars or agents alongside deployed services and need to be accessible over the network to your instance of the Apollo MCP Server.

Update your config.yaml to configure the MCP Server with the telemetry section. This will point the MCP Server at your collector on startup.

```yaml
telemetry:
  exporters:
    metrics:
      otlp:
        endpoint: "http://localhost:4317"
        protocol: "grpc"
    tracing:
      otlp:
        endpoint: "http://localhost:4317"
        protocol: "grpc"
```
With this configuration, the server will send traces and metrics to an OpenTelemetry Protocol compatible collector running at http://localhost:4317.

## Configuration Reference

The OpenTelemetry integration is configured via the `telemetry` section in your config.yaml file.

### **Basic Configuration**

| Parameter | Type | Description | Default |
| :--- | :--- | :--- | :--- |
| service_name | String | The service name in telemetry data. | `apollo-mcp-server` |
| version | String | The service version in telemetry data. | Current crate version |
| exporters | Object | Configuration for telemetry exporters. | `null` (no telemetry) |

### **Environment Variables**

| Variable | Description | Default |
| :--- | :--- | :--- |
| `ENVIRONMENT` | Sets the deployment environment for telemetry resource attributes. | `development` |

### **Automatic Resource Attributes**

The server automatically sets these OpenTelemetry resource attributes:

| Attribute | Value | Purpose |
| :--- | :--- | :--- |
| `service.name` | From `service_name` config | Service identification |
| `service.version` | From `version` config | Service version tracking |
| `deployment.environment.name` | From `ENVIRONMENT` variable | Environment correlation (dev, staging, prod) |

### **Exporters Configuration**

`exporters`

| Parameter | Type | Description |
| :--- | :--- | :--- |
| metrics | Object | Configuration for metrics exporters. |
| tracing | Object | Configuration for tracing exporters. |

`metrics.otlp` / `tracing.otlp`

| Parameter | Type | Description | Default |
| :--- | :--- | :--- | :--- |
| endpoint | String | The OTLP endpoint to send data to. | `http://localhost:4317` |
| protocol | String | The OTLP protocol to use. Supported values are `grpc` and `http/protobuf`. | `grpc` |


## Emitted Metrics

The server emits the following custom metrics, which are invaluable for monitoring and alerting. All duration metrics are in milliseconds.

| Metric Name | Type | Description | Attributes |
|---|---|---|---|
| `apollo.mcp.initialize.count` | Counter | Incremented for each `initialize` request. | (none) |
| `apollo.mcp.list_tools.count` | Counter | Incremented for each `list_tools` request. | (none) |
| `apollo.mcp.get_info.count` | Counter | Incremented for each `get_info` request. | (none) |
| `apollo.mcp.tool.count` | Counter | Incremented for each tool call. | `tool_name`, `success` (bool) |
| `apollo.mcp.tool.duration` | Histogram | Measures the execution duration of each tool call. | `tool_name`, `success` (bool) |
| `apollo.mcp.operation.count`| Counter | Incremented for each downstream GraphQL operation executed by a tool. | `operation.id`, `operation.type` ("persisted_query" or "operation"), `success` (bool) |
| `apollo.mcp.operation.duration`| Histogram | Measures the round-trip duration of each downstream GraphQL operation. | `operation.id`, `operation.type`, `success` (bool) |

In addition to these custom metrics, the server also emits standard [HTTP server metrics](https://opentelemetry.io/docs/specs/semconv/http/http-metrics/) (e.g., `http.server.duration`, `http.server.active_requests`) courtesy of the `axum-otel-metrics` library.


## Emitted Traces

Spans are generated for the following actions:

*   **Incoming HTTP Requests**: A root span is created for every HTTP request to the MCP server.
*   **MCP Handler Methods**: Nested spans are created for each of the main MCP protocol methods (`initialize`, `call_tool`, `list_tools`).
*   **Tool Execution**: `call_tool` spans contain nested spans for the specific tool being executed (e.g., `introspect`, `search`, or a custom GraphQL operation).
*   **Downstream GraphQL Calls**: The `execute` tool and custom operation tools create child spans for their outgoing `reqwest` HTTP calls, capturing the duration of the downstream request. The `traceparent` and `tracestate` headers are propagated automatically, enabling distributed traces.
